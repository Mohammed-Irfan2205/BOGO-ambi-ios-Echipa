#!/usr/bin/env python

"""

Use Twitter API to grab user information from list of organizations; 
export text file

Uses Twython module to access Twitter API

"""

import sys
import string
import simplejson
from twython import Twython #Using this  TwythonLibrary to use Twitter API.
import time
import json

#Library to use Mongo DB
import pymongo
from pymongo import MongoClient

#WE WILL USE THE VARIABLES DAY, MONTH, AND YEAR FOR OUR OUTPUT FILE NAME
import datetime
now = datetime.datetime.now()
day=int(now.day)
month=int(now.month)
year=int(now.year)


#FOR OAUTH AUTHENTICATION -- NEEDED TO ACCESS THE TWITTER API
t = Twython(app_key='Aj75DDCB608ERaHyMiWj8xV7t', #REPLACE 'APP_KEY' WITH YOUR APP KEY, ETC., IN THE NEXT 4 LINES
    app_secret='pT4w1VJPORy0RlEVx45AWvc8RNmwOsJnIYyzDFPGIysKcRer40',
    oauth_token='1687216410-lLpY8pQjialj94OL3Hsm9h7hXpl16IdmLhsOOGc',
    oauth_token_secret='WXWCt23WpgM8quShFLPL35lBMteu4uxj4k1ogYEcimbOh')
	
#Connecting to Mongo DB
client = MongoClient('localhost',27017)
db = client['NEWSdata']
#SocialData = db['NEWSdatacollection']
TwitterData = db.TwitterData


#The above data is generated by requesting an application on developer twitter URL.
 
#NAME OUR OUTPUT FILE - %i WILL BE REPLACED BY CURRENT MONTH, DAY, AND YEAR
outfn = "I:/IrfanS_WorkStation/SocialMediaApplication/twitter_BiharWithBJP_data_3_%i.%i.%i.txt" % (now.month, now.day, now.year)
 
#INITIALIZE OUTPUT FILE
outfp = open(outfn, "w")

#REPLACE WITH YOUR LIST OF TWITTER USER IDS

#id = "145125358"
id ="18354016,177547780,37034483,15537849,759251,6509832,134758540,19897138,266714730,742143,5402612,2557521,265902729,206037540,361716106,19144836,18071358,225012752,23405846,15896162,475906703,1056850669,36327407,1447949844,2695009326,17710740,1100927498,4970411,972651,428333,18735898,14075928,14293310,14800270,2890961,816653,1344951,3108351,15736190,2707054218,14780915,30313925,3064617094,300974581,807095,1367531,2884771,5988062,14372486,1652541"

#id = "18354016,177547780,37034483"
#id="#BiharWithBJP"

fields = "id screen_name name created_at url followers_count friends_count statuses_count favourites_count listed_count contributors_enabled description protected location lang expanded_url text time_zone geo_enabled verified coordinates geo place id_str".split()
j=1
#ACCESS THE LOOKUP_USER METHOD OF THE TWITTER API -- GRAB INFO ON UP TO 100 IDS WITH EACH API CALL
#THE VARIABLE USERS IS A JSON FILE WITH DATA ON THE 32 TWITTER USERS LISTED ABOVE
#If we have to search using screen_name , we can simply replace user_id with screen_name in the below line(Line no 40)
for i in range(0,120):
	print i
	users = t.lookup_user(user_id = id)
	#data=t.search(q=id,count=1,result_type='recent',lang='en',max_id=None)
	#print users
	for search_metadata in users:
		r = {}
		status = {}
		for f in fields:
			r[f] = ""
		#ASSIGN VALUE OF 'ID' FIELD IN JSON TO 'ID' FIELD IN OUR DICTIONARY
		r['id'] = search_metadata['id']
		#SAME WITH 'SCREEN_NAME' HERE, AND FOR REST OF THE VARIABLES
		r['screen_name'] = search_metadata['screen_name']
		r['name'] = search_metadata['name']
		r['created_at'] = search_metadata['created_at']
		r['url'] = search_metadata['url']
		r['followers_count'] = search_metadata['followers_count']
		r['friends_count'] = search_metadata['friends_count']
		r['statuses_count'] = search_metadata['statuses_count']
		r['favourites_count'] = search_metadata['favourites_count']
		r['listed_count'] = search_metadata['listed_count']
		r['contributors_enabled'] = search_metadata['contributors_enabled']
		r['description'] = search_metadata['description']
		r['protected'] = search_metadata['protected']
		r['location'] = search_metadata['location']
		r['lang'] = search_metadata['lang']	
		if 'status' in search_metadata:
			#print "In Status"
			status = search_metadata['status']
			#r['status'] = search_metadata['status']
			for element in status:
				#print "In Element"
				r['text'] = status['text']
				r['coordinates'] = status['coordinates']
				r['place'] = status['place']
				r['geo'] = status['geo']
				#entities = search_metadata['entities']
				r['id_str'] = status['id_str']
		r['time_zone'] = search_metadata['time_zone']
		r['geo_enabled'] = search_metadata['geo_enabled']
		r['verified'] = search_metadata['verified']
		
		#NOT EVERY ID WI LL HAVE A 'URL' KEY, SO CHECK FOR ITS EXISTENCE WITH IF CLAUSE
		if 'url' in search_metadata['entities']:
			r['expanded_url'] = search_metadata['entities']['url']['urls'][0]['expanded_url']
		else:
			r['expanded_url'] = ''
		
		try:
			print j
			j = j +1
			TwitterData.insert(r)
		except:
			print "Duplicate"
			continue	
	time.sleep(30)    
client.close()
outfp.close()    
